include "Environment.conf"
include "Exploration.conf"
include "Architecture.conf"
include "Training.conf"

ppo_default {
    env = continuous-grid
    run = PPO
    local_dir = /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/obst/PPO/
    checkpoint_freq = 10
    stop {
        training_iteration = 400
    }
    config {
        num_gpus = 1
        timesteps_per_iteration = 1000
        num_workers = 4
        log_level = WARNING
        framework = torch
    }    
}

ppo_v0 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS}
}

ppo_arch3_feats9 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/
    config = ${envconf_v2_feats_v9} ${arch_v3}
}

############################
### features_experiments ###
############################
ppo_featsv1 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v1}
}
ppo_featsv2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v2}
}
ppo_featsv3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v3}
}
ppo_featsv4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v4}
}
ppo_featsv5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v5}
}
ppo_featsv6 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v6}
}
ppo_featsv7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v7}
}
ppo_featsv8 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v8}
}
ppo_featsv9 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    config = ${envconf_v2_feats_v9}
}

################################
### architecture experiments ###
################################
ppo_archv3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v3}
}
ppo_archv3lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v3_lstm}
}
ppo_archv3lstm2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v3_lstm2}
}
ppo_archv3lstm3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v3_lstm3}
}
ppo_archv4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v4}
}
ppo_archv4lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v4_lstm}
}
ppo_archv5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v5}
}
ppo_archv5lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/arch
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${arch_v5_lstm}
}


###############################
### exploration experiments ###
###############################
ppo_expl_gaus = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/explore
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${expl_Gaussdefault}
}
ppo_expl_oun = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/explore
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${expl_OUNdefault}
}
ppo_explv1 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/explore
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${expl_v1}
}
ppo_explv4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/explore
    config = ${envconf_v2_obst_noNorm_dynLSpd_dynFPS} ${expl_v4}
}

###############################
###          ENV 4          ###
# env4 == obst_dynLSpd_dynFPS #
###############################


ppo_env4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4}
}

ppo_env4_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4} ${train_v5v2_sqd}
}

ppo_env4_featsv2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v2}
}
ppo_env4feats2v2_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v2v2} ${train_v5v2_sqd}
}
ppo_env4_featsv9v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v9v2}
}

ppo_env4feats9v3_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v9v3} ${train_v5v2_sqd}
}
ppo_env4_featsv10 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10}
}
# бывший v11
ppo_env4_feats10v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v2}
}
ppo_env4_feats10v3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v3} 
}
ppo_env4_feats10v4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v4} 
}
ppo_env4_feats10v5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v5} 
}
ppo_env4_feats10v6 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v6} 
}
ppo_env4_feats10v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7} 
}
ppo_env4_feats10v8 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v8} 
}
ppo_env4_feats10v9 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v9} 
}
ppo_env4_feats10v10 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v10} 
}
ppo_env4_feats10v11 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v11} 
}
ppo_env4_feats10v12 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v12} 
}
ppo_env4_feats10v13 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v13} 
}
ppo_env4_feats7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v7} 
}
ppo_env4_feats11 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v11} 
}

ppo_env4_feats12 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v11}
}


ppo_env5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v5}
}
ppo_env5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v5v2}
}


################################
###    Env v4, feats 10v2    ###
### Architecture experiments ###
################################
ppo_env4feats10v2_arch5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v2_arch
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v2}  ${arch_v5}
}

################################
###    Env v4, feats 10v7    ###
### Architecture experiments ###
################################
ppo_env4feats10v7_arch5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_arch
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${arch_v5}
}

ppo_env4feats10v7_arch6 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_arch
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${arch_v6}
}
################################
###    Env v4, feats 10v7    ###
###   Training experiments   ###
################################
ppo_env4feats10v7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${train_v5v2_sqd}
}
ppo_env4feats10v7_train5v3 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${train_v5v3_sqd}
}
ppo_env4feats10v7_train5v4 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${train_v5v4_sqd}
}
ppo_env4feats10v7_train5v5 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v10v7}  ${train_v5v5_sqd} 
}
################################
###    Env v4, feats 12    ###
###   Training experiments   ###
################################
ppo_env4feats12_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v12}  ${train_v5v2_sqd} 
}

ppo_env4feats12_train5v6 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4/PPO/env4feats12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4_feats_v12}  ${train_v5v6_sqd} 
}

################################
###     Env v4v2             ###
###    Feature experiments   ###
################################
ppo_env4v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2}
}

ppo_env4v2feats10v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/env4v2feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2_feats_v10v7}
}
ppo_env4v2feats2v2_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2_feats_v2v2} ${train_v5v2_sqd}
}

ppo_env4v2feats9v3_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2_feats_v9v3} ${train_v5v2_sqd}
}

################################
###    Env v4v2, feats 10v7  ###
###   Training experiments   ###
################################
ppo_env4v2_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2}  ${train_v5v2_sqd}
}
ppo_env4v2feats10v7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env4v2/PPO/env4v2feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v4v2_feats_v10v7}  ${train_v5v2_sqd}
}

################################
###    Env v7               ###
###   Feature experiments   ###
################################

ppo_env7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7}
}


ppo_env7_feats10v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v10v7}
}


ppo_env7feats2v2_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v2v2} ${train_v5v2_sqd}
}

ppo_env7feats9v3_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats2v2_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v9v3} ${train_v5v2_sqd}
}
################################
###    Env v7, feats 10v7    ###
###   Training experiments   ###
################################
ppo_env7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7}  ${train_v5v2_sqd}
}

ppo_env7feats10v7_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/grartem/RL_robots/RL_robotSim/results/FollowerContinuous/env7/PPO/feats10v7_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v7_feats_v10v7}  ${train_v5v2_sqd}
}

################################
###    Env v8, feats 12      ###
###   Training experiments   ###
################################

ppo_env8feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env8/PPO/feats_v12_train
#     local_dir: /home/sheins/rl-test/RL_robotSim/results/FollowerContinuous/env8/PPO/feats_v12_train

    stop {
        training_iteration = 400
    }
    config = ${envconf_v8_feats_v12}  ${train_v5v7_sqd}
}

ppo_env8feats_v12_train5v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env8/PPO/feats_v12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v8_feats_v12}  ${train_v5v2_sqd}
}

ppo_env8v2feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env8v2/PPO/feats_v12_train
#     local_dir: /home/sheins/rl-test/RL_robotSim/results/FollowerContinuous/env8/PPO/feats_v12_train

    stop {
        training_iteration = 400
    }
    config = ${envconf_v8v2_feats_v12}  ${train_v5v7_sqd}
}

ppo_env8v2feats_v12_v1_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env8v2/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v8v2_feats_v12v1}  ${train_v5v7_sqd}
}

###########################################################
#################### ENVIROMENT V9 ########################
###########################################################

ppo_env9v1feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env9v2feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v2_feats_v12}  ${train_v5v7_sqd}
}

ppo_env9v3feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v3_feats_v12}  ${train_v5v7_sqd}
}

ppo_env9v1_d1_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env9v4feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v4_feats_v12}  ${train_v5v7_sqd}
}
###################
## TODO : debug
###################

ppo_env9v1_d2_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env9v4_d1_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v4_feats_v12}  ${train_v5v7_sqd}
}


ppo_env9v5_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v4_feats_v12}  ${train_v5v7_sqd}
}

ppo_env9v6_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env9/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v9v1_feats_v12}  ${train_v5v7_sqd}
}

################################
###    Env v10, feats 12     ###
###   Training experiments   ###
################################

ppo_env10v1feats_v12_train5v2_use_lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env10/PPO/feats_v12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v10v1_feats_v12}  ${train_v5v2_sqd}{
        model = {
            use_lstm = True
        }
    }
}


ppo_env10v1feats_v12_train5v7_use_lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env10/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v10v1_feats_v12}  ${train_v5v7_sqd}{
        model = {
            use_lstm = True
        }
    }
}
######################################


ppo_env10v2_feats_v12_train5v2_use_lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env10/PPO/feats_v12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v10v2_feats_v12}  ${train_v5v2_sqd} ${arch_v7_lstm}
}


# ppo_env10v2feats_v12_train5v7_use_lstm = ${ppo_default}  {
#     local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env10/PPO/feats_v12_train
#     stop {
#         training_iteration = 400
#     }
#     config = ${envconf_v10v1_feats_v12} ${train_v5v7_sqd} ${arch_v7_lstm}
# }

ppo_env10v3feats_v12_train5v2_use_lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env10/PPO/feats_v12_train
    stop {
        training_iteration = 800
    }
    config = ${envconf_v10v3_feats_v12}  ${train_v5v2_sqd} ${arch_v7_lstm}
}

######################################
####### ENV 11 ##############
######################################

ppo_env11v1_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env11/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v11v1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env11v2_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env11/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v11v2_feats_v12}  ${train_v5v7_sqd}
}

ppo_env11v3_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env11/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v11v3_feats_v12}  ${train_v5v7_sqd}
}
######################################################################################################################
######################################
####### ENV 12 ##############
######################################
#Был запущен
ppo_env12v1_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env12/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v12v1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env12v1_feats_v12_feats_v1_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env12/PPO/feats_v12_train_feats_v1
    stop {
        training_iteration = 400
    }
    config = ${envconf_v12v1_feats_v12_feats_v1}  ${train_v5v7_sqd}
}

ppo_env12v2_feats_v12_feats_v1_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env12/PPO/feats_v12_train_feats_v1
    stop {
        training_iteration = 400
    }
    config = ${envconf_v12v2_feats_v12_feats_v1}  ${train_v5v7_sqd}
}
######################################
####### ENV 13 ##############
######################################
#Был запущен
ppo_env13v1_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env13/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v13v1_feats_v12}  ${train_v5v7_sqd}
}
#Был запущен
ppo_env13v2_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env13/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v13v2_feats_v12}  ${train_v5v7_sqd}
}
##################################
### 05.09.2022
##################################
ppo_env13v3_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env13/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v13v3_feats_v12}  ${train_v5v7_sqd}
}

ppo_env13v1_feats_v12_feat_v1_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env13/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v13v1_feats_v12_feats_v1}  ${train_v5v7_sqd}
}

ppo_env13v3_feats_v12_feat_v1_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env13/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v13v3_feats_v12_feats_v1}  ${train_v5v7_sqd}
}

##################################
### 06.09.2022 env 14 ############
##################################
ppo_env14v1_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env14/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v14v1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env14v1_feats_v12_feats_v1_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env14/PPO/feats_v12_train_feats_v1
    stop {
        training_iteration = 400
    }
    config = ${envconf_v14v1_feats_v12_feats_v1}  ${train_v5v7_sqd}
}

ppo_env14v1_feats_v12_feats_v1_train5v7_use_lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env14/PPO/feats_v12_train_feats_v1
    stop {
        training_iteration = 800
    }
    config = ${envconf_v14v1_feats_v12_feats_v1}  ${train_v5v2_sqd}{
        model = {
            use_lstm = True
            lstm_use_prev_action = True
            lstm_use_prev_reward = True
        }
    }
}

##################################
### 08.09.2022 env 15 ############
##################################
ppo_env15v1_feats_v13_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env15/PPO/feats_v13_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v15v1_feats_v13}  ${train_v5v7_sqd}
}

ppo_env15v2_feats_v13_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env15/PPO/feats_v13_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v15v2_feats_v13}  ${train_v5v7_sqd}
}


######################################################
### 08.09.2022 env 16 исправление косяков ############
######################################################
ppo_env16v1_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env16/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v16v1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env16v2_feats_v12_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env16/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v16v2_feats_v12}  ${train_v5v7_sqd}
}

ppo_env16v2_feats_v12_feats_v1_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env16/PPO/feats_v12_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v16v2_feats_v12_feats_v1}  ${train_v5v7_sqd}
}

############################################################
############ не запущенные еще #############################
ppo_env17v1_feats_v13_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env17/PPO/feats_v13_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v17v1_feats_v13}  ${train_v5v7_sqd}
}

ppo_env17v2_feats_v13_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env17/PPO/feats_v13_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v17v2_feats_v13}  ${train_v5v7_sqd}
}

ppo_env17v2_feats_v14_train5v7 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env17/PPO/feats_v14_train
    stop {
        training_iteration = 400
    }
    config = ${envconf_v17v2_feats_v14}  ${train_v5v7_sqd}
}


################### ENV 18 base ############################
############################################################
################### LSTM ###################################

ppo_env18v1_feats_v12_train5v2_lstmv1 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env18/PPO/feats_v12_train_lstm
    stop {
        training_iteration = 800
    }
    config = ${envconf_v18v1_feats_v12}  ${train_v5v2_sqd} ${arch_v7_lstmv1}
}

ppo_env18v1_feats_v12_train5v2_lstmv2 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env18/PPO/feats_v12_train_lstm
    stop {
        training_iteration = 800
    }
    config = ${envconf_v18v1_feats_v12}  ${train_v5v2_sqd} ${arch_v7_lstmv2}
}

ppo_env18v1_feats_v12_train5v2_lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env18/PPO/feats_v12_train_lstm
    stop {
        training_iteration = 800
    }
    config = ${envconf_v18v1_feats_v12}  ${train_v5v2_sqd} ${arch_v7_lstm}
}


##############################################################

ppo_env18v1_feats_v12_train5_lstmv2 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env18/PPO/feats_v12_train_lstm2
    stop {
        training_iteration = 800
    }
    config = ${envconf_v18v1_feats_v12}  ${train_v5_sqd} ${arch_v7_lstmv2}
}


ppo_env18v1_feats_v12_train5_lstm = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env18/PPO/feats_v12_train_lstm2
    stop {
        training_iteration = 800
    }
    config = ${envconf_v18v1_feats_v12}  ${train_v5_sqd} ${arch_v7_lstm}
}

ppo_env18v1_feats_v12_train5_lstm8v1 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env18/PPO/feats_v12_train_lstm2
    stop {
        training_iteration = 800
    }
    config = ${envconf_v18v1_feats_v12}  ${train_v5_sqd} ${arch_v8_lstmv1}
}
##############################################################
##############################################################

ppo_env18v1_feats_v12_train5_lstm8v2 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env18/PPO/feats_v12_train_lstm
    stop {
        training_iteration = 800
    }
    config = ${envconf_v18v1_feats_v12}  ${train_v5_sqd} ${arch_v8_lstmv2}
}
# перепроверить что ниже
ppo_env18v1_feats_v12_train5v2_arch8 = ${ppo_default}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env18/PPO/feats_v12_train_arch8
    stop {
        training_iteration = 800
    }
    config = ${envconf_v18v1_feats_v12}  ${train_v5v2_sqd} ${arch_v8}
}

#################################################
#################################################\

############# ENV 19 with faster bear and obs 70 #################

ppo_default_v1 = ${ppo_default}  {
    checkpoint_freq = 5
}

# 19v1 не запущен

ppo_env19v1_feats_v12_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env19/PPO/feats_v12_train_35
    stop {
        training_iteration = 400
    }
    config = ${envconf_v19v1_feats_v12}  ${train_v5v7_sqd}
}
######################

ppo_env19v2_feats_v12_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env19/PPO/feats_v12_train_35
    stop {
        training_iteration = 400
    }
    config = ${envconf_v19v2_feats_v12}  ${train_v5v7_sqd}
}

ppo_env19v3_feats_v12_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env19/PPO/feats_v12_train_70
    stop {
        training_iteration = 400
    }
    config = ${envconf_v19v3_feats_v12}  ${train_v5v7_sqd}
}


ppo_env19v4_feats_v12_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env19/PPO/feats_v12_train_70
    stop {
        training_iteration = 400
    }
    config = ${envconf_v19v4_feats_v12}  ${train_v5v7_sqd}
}
######################################
############# env 20 #################
ppo_env20v2_feats_v12_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env20/PPO/feats_v12_train_35
    stop {
        training_iteration = 400
    }
    config = ${envconf_v20v2_feats_v12}  ${train_v5v7_sqd}
}

ppo_env20v4_feats_v12_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env20/PPO/feats_v12_train_70
    stop {
        training_iteration = 400
    }
    config = ${envconf_v20v4_feats_v12}  ${train_v5v7_sqd}
}

ppo_env20v2_feats_v12_feats_v1_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env20/PPO/feats_v12_feats_v1_train_35
    stop {
        training_iteration = 400
    }
    config = ${envconf_v20v2_feats_v12_feats_v1}  ${train_v5v7_sqd}
}

######################################

ppo_env20v1_feats_v12_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env20/PPO/feats_v12_train_35
    stop {
        training_iteration = 400
    }
    config = ${envconf_v20v1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env20v1_1_feats_v12_train5v7 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env20/PPO/feats_v12_train_35
    stop {
        training_iteration = 400
    }
    config = ${envconf_v20v1_1_feats_v12}  ${train_v5v7_sqd}
}

ppo_env20v1_feats_v12_train5v7_1500 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env20/PPO/feats_v12_train_35
    stop {
        training_iteration = 1500
    }
    config = ${envconf_v20v1_feats_v12}  ${train_v5v7_sqd}
}

################## TEST CONFIR ######################

# ppo_env20v1_feats_v12_train5v7_test = ${ppo_default_v1}  {
#     local_dir: /home/sheins/rl_robot/RL_robotSim/results/FollowerContinuous/env20/PPO/feats_v12_train_35
#     stop {
#         training_iteration = 1500
#     }
#     config = ${envconf_v20v1_feats_v12}  ${train_v5v7_sqd}
# }

# ppo_env21v1_feats_v15_test = ${ppo_default_v1}  {
#     local_dir: /home/sheins/rl_robot/RL_robotSim/results/FollowerContinuous/env20/PPO/feats_v12_train_35
#     stop {
#         training_iteration = 300
#     }
#     config = ${envconf_v21v1_feats_v15_test} ${train_v5v2_sqd} ${arch_v7_lstm}
# }
################## EXPERIMENTS CONFIG ######################

ppo_env21v1_feats_v15_lstmv7v2 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env21/PPO/feats_v12_train_35
    stop {
        training_iteration = 500
    }
    config = ${envconf_v21v1_feats_v15} ${train_v5v2_sqd} ${arch_v9_lstmv1}
}

ppo_env21v2_feats_v15_lstmv7v2 = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env21/PPO/feats_v12_train_35
    stop {
        training_iteration = 500
    }
    config = ${envconf_v21v2_feats_v15} ${train_v5v2_sqd} ${arch_v9_lstmv1}
}

ppo_env21v1_feats_v15_v5v7_sqd = ${ppo_default_v1}  {
    local_dir: /s/ls4/users/slava1195/rl_rob/RL_robotSim/results/FollowerContinuous/env21/PPO/feats_v12_train_35
    stop {
        training_iteration = 300
    }
    config = ${envconf_v21v1_feats_v15} ${train_v5v7_sqd}
}
