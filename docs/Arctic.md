## Краткое описание возможностей интеграции нейросетевой модели для задачи следования
Здесь представлено описание интеграции системы управления движением робота для задачи следования в 3D среду. 
Программная интеграция находится в [папке](../src/arctic_gym)
В ней представлен основной функционал по интеграции данной модели в среду Gazebo с мобильным роботом, который 
вы можете использовать в собственном проекте.

## Основные модули
- [src/arctic_gym/run.py](../src/arctic_gym/run.py) - основной файл при запуске решения задачи следования. 
Запуская данный файл происходит запуск модели и получение основной информации из среды. Также, присутствует вспомогательный 
функционал в виде системы безопасности робота.
- [src/arctic_gym/arctic_env/arctic_env.py](../src/arctic_gym/arctic_env/arctic_env.py) - файл содержащий все скрипты для 
осуществления рещения задачи следования. Получение данных лидара, камеры, распознавание объектов на изображении и т.д.
- [src/arctic_gym/gazebo_utils/gazebo_tracker.py](../src/arctic_gym/gazebo_utils/gazebo_tracker.py) - файл содержащий классы,
реализующие сенсоры, адаптированные под 3D среду.
- [src/arctic_gym/server/arctic_server.py](../src/arctic_gym/server/arctic_server.py) - файл для запуска Flask сервера с моделью. 
В данную [папку](../src/arctic_gym/server) помещаются checkpoints полученных моделей из 2D среды.



## Особенности использования

Для использования данного блока управления робот пользователю необходимо осуществить первоначальную настройку. 
Программный модуль, использующий RL-модель следования, настроен с учетом использования симуляционного 
мира ROS Gazebo, в котором реализован определенный робот с лидаром и вращающейся камерой.
Для запуска демонстрации пользователю необходимо создать собственный симуляционный мир с мобильным колесным роботом,
у которого на своем борту будут присутствовать камера и лидар. Предварительно пользователь должен иметь:
- Мир ROS Gazebo (как пример)
- Робот с камерой и лидаром
- Object detection (например YOLO)

В описании к соответствующим модулям представлено описание функций, которые необходимо настроить для 
взаимодействия с собственной средой пользователя.  

## Основной файл запуска системы управления с помощью Rl-модели

[Скрипт run.py](../src/arctic_gym/run.py) осуществляет запуск системы управления и решение задачи следования в симуляционном мире.
Функция main запускает задачу следования и выполняет обмен наблюдений, награды и действий. Также, здесь реализована простейшая 
система безопасности и информирования в случае нештатных ситуаций. 

### Структура системы безопасности:
- Остановка ведущего в случае его нахождения слишком далеко при следовании; 
- Экстренная остановка ведомого, в случае близкого нахождения к ведущему;
- Запуск режима поиска ведущего в случае его длительной потери из поля зрения:
  - В случае длительной потери ведущего, ведомый начинает осуществлять поиск посредством запуска вращения камеры. 
  Функция для вращения камерой _rotate_the_camera. Прекращает в случае нахождения ведущего.  
  - При наличии точек истории маршрута ведущего, ведомый после потери его из поля зрения, будет продолжать движение по 
  маршруту, а затем произведет остановку. Робот будет осуществлять вращение камерой и стоять на месте до тех пор, пока 
  не найдет ведущего. 
  - В случае ожидания больше 30 секунд, задача завершится автоматически. 


## Класс среды, адаптированной к 3D среде

В файле [arctic_env.py](../src/arctic_gym/arctic_env/arctic_env.py) содержатся основная структура в соответствии с 
[follow_the_leader_continuous_env](../src/continuous_grid_arctic/follow_the_leader_continuous_env.py), адаптированная к 
3D среде. В данном классе реализованы различные функции для взаимодействия с роботом, камерой, лидаром, вычисление маршрута
и другое. 

Основные функции класса: 
- reset - функция сброса к начальным условиям параметров класса
- step - функция обработки одного шага симуляции, обработка информации и вычисление необходимых значений.
- _get_xy_lead_from_length_phi - функция вычисления координат ведущего на основе информации о расстоянии и угле отклонения
- _calculate_points_angles_objects - функция вычисления углов по значениям bounding box. 
- _get_ssd_lead_information - Функция отправляющая изображение с камеры на Flask сервер с object detection и получающая результаты
        детектирования объектов. 
        self.sub.get_from_follower_image() - обращается к топику ROS за изображением с камеры.
        Пользователю необходимо передавать в данную функцию собственное изображение, которое отправляется
        в собственную модель детектирования объектов посредством post запроса.
        Метод используется в reset и step, в тех местах пользователю необходимо изменить подачу изображения или прописать 
        собственный топик ROS. 
        Пример, где пользователь должен заменить модель:
        ```
        results = requests.post('http://localhost:3333/detection', data=data, timeout=15.0)
        ```

- _get_lidar_points - функция получения облака точек с лидара. Пользователю необходимо исправить ее для 
      использования собственного лидара. Необходимо прописать топик для подключения к лидару ROS Gazebo.
- _get_obs_points - Функция обрабатывающая облако точек лидара для веделения препятствий. Первоначально функция фильтрует точки
        поверхности методом CSF (Cloth Simulation Filter), оставляя только точки препятствий. Далее, нормализует их 
        относительно локального положения ведомого. После, полученный список проэцируется на 2D плоскость, уменьшается
        дискретность и округляются значения координат оставшихся точек. Список добавляется вторым соседними мнимыми точками
        в непосредственной близости для формирования отрезков, которые в дальнейшем проверяются лидарными признаками 
        нейросетевой моделью.
- _calculate_length_to_leader - Функция определения расстояния до ведущего на основе обработки результата детектирования объектов на изображении
        и облака точек лидара. На основе полученных bounding box происходит сопоставление их с точками лидара, используя
        результат функции calculate_points_angles_objects. В результате, из всего облака точек лидара происходит выделение 
        только точек лидара, использую BB и углы из calculate_points_angles_objects. 
        Далее, на основе полученной информации берется ближайшая точка, и на основе нее вычисляется расстояние до ведущего. 
        Также, из всего облака точек, удаляются точки ведущего и в дальнейшем не учитвваются в обработке препятствий.
- _get_camera_lead_info - Функция определения угла отклонения ведущего относительно ведомого на основе информации с камеры и расстоянии до 
        ведущего. Возвращает результат о расстояние и угле отклонения ведущего в локальных координатах
- _get_delta_position - Функция определения перемещения за одну итерацию. Определяется перемещение ведомого по координатам
      x и y за один step.
- _is_done - Функция проверки статусов выполнения задачи и нештатных ситуаций.
- _compute_reward - расчет награды 

## Классы сенсоров для 3D мира

В [файле gazebo_tracker.py](../src/arctic_gym/gazebo_utils/gazebo_tracker.py) реализованы сенсоры из 2D среды, 
адаптированный к 3D среде. В файле на данный момент находятся 4 сенсора:
- GazeboLeaderPositionsTracker
- GazeboLeaderPositionsTracker_v2
- GazeboLeaderPositionsTrackerRadar
- GazeboLeaderPositionsCorridorLasers

### Сенсоры для отслеживания положения ведущего на основе признаков радара
Для признаков рада было реализовано два сенсора: GazeboLeaderPositionsTracker и GazeboLeaderPositionsTrackerRadar.

 Класс **GazeboLeaderPositionsTracker** реализует отслеживание ведущего и формирование его истории маршрута, 
используя информацию о положении ведущего, ведомого (работая в локальных координатах всегда [0, 0]), и значения 
перемещения (delta_x и delta_y).

Класс **GazeboLeaderPositionsTrackerRadar** реализует признаки радара, адаптированные к 3D среде. На вход класс получает
информацию о положении ведущего, ведомого (работая в локальных координатах всегда [0, 0]), и значения 
истории маршрута ведущего, а на выходе формирует нормированные входные признаки для нейросетевой модели. 


### Сенсоры для отслеживания положения ведущего на основе признаков "лучевого сенсора"
Для признаков "лучевого сенсора" было реализовано два сенсора: GazeboLeaderPositionsTracker_v2 и GazeboLeaderPositionsCorridorLasers.

Класс **GazeboLeaderPositionsTracker_v2** реализует отслеживание ведущего и формирование его истории маршрута, 
используя информацию о положении ведущего, ведомого (работая в локальных координатах всегда [0, 0]), и значения 
перемещения (delta_x и delta_y). В результате работы сенсора формируется история маршрута ведущего, аналогично 
GazeboLeaderPositionsTracker, а также, коридор следования, который строит левую и правую стенку вокруг безопасной зоны 
следования. Признаки "лучевого сенсора" опираются на информацию о расстоянии до данного коридора.


Класс **GazeboLeaderPositionsCorridorLasers** реализует признаки радара, адаптированные к 3D среде. На вход класс получает
информацию о положении ведущего, ведомого (работая в локальных координатах всегда [0, 0]), значения 
истории маршрута ведущего, коридор следования и список спроецированных на 2D плоскость точек препятствий. 
На выходе формирует нормированные входные признаки для нейросетевой модели. 

**ВАЖНО**
GazeboLeaderPositionsTracker_v2 и GazeboLeaderPositionsCorridorLasers обладают различными параметрами, например: 
период сохранения точек истории маршрута ведущего, длина и ширина коридора, период удаления истории точек для коридора 
следования и другие. Данные параметры были настроены для определенного робота с учетом особенностей симуляции и т.д.

Пример параметров GazeboLeaderPositionsTracker_v2:
- max_dev = 2 - ширина коридора
- max_distance = 24 - максимальное удаление ведомого от ведущего
- saving_period = 3 - период сохранения точек маршрута ведущего

Пример параметров GazeboLeaderPositionsCorridorLasers:
- laser_length = 4 - длинна лучей сенсора

Параметры [arctic_env.py](../src/arctic_gym/arctic_env/arctic_env.py) при настройке следования:
- time_for_action = 0.3 - параметр времени выполнения действия

Параметры мира:
- ведущий размерами длинной 2 метра, шириной 1 метр
- ведомый размерами длинной 1 метра, шириной 1 метр
- ведомый обладает вращающейся камерой на 360 градусов
- ведомый обладает лидаром


Пользователь может создавать собственные сенсоры и входные признаки для модели, в таком случае их необходимо реализовывать 
в [файле gazebo_tracker.py](../src/arctic_gym/gazebo_utils/gazebo_tracker.py) как новый класс. 


## Сервер RL-модели

В [файле arctic_server.py](../src/arctic_gym/server/arctic_server.py) находится параметры использования нейросетевой 
модели следования. Пользователю необходимо настраивать все данные параметры под собственный сенсоры, 
в случае написания собственных в [файле gazebo_tracker.py](../src/arctic_gym/gazebo_utils/gazebo_tracker.py), 
либо использовать значения по умолчанию. В данной среде представлена конфигурация для "лучевого сенсора" с 7 лучами. 

В частности, конфигурации для исправления пользователям:
- Путь до файла с конфигурациями модели
```
PATH = os.path.join(os.path.dirname(__file__), "config", "FollowerContinuous", "PPO_dyn_obst.conf")
```

- Путь для необходимых чекпоинтов
```
CHECKPOINT = os.path.join(os.path.dirname(__file__), "checkpoints", "ppo_featsv2", "checkpoint_000340", "checkpoint-340")
```
- Конфиг количество входных признаков (7 лучей)
```
    sensor_config = {
        'lasers_sectors_numbers': 7
    }
```
- Пространство наблюдений
```
    observation_space = Box(
        np.zeros(sensor_config['lasers_sectors_numbers'], dtype=np.float32),
        np.ones(sensor_config['lasers_sectors_numbers'], dtype=np.float32)
    )
```
- Конфиг модели, который использовался при обучении модели
```
    CONFIG = configs["ppo_env4feats12_train5v6"].as_plain_ordered_dict()
```
